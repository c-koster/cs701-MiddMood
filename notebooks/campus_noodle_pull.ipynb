{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Header  \\\n",
      "0  Breaking: Leaked Documents Show MCAB promises ...   \n",
      "1  Virtue Field House Track Converted to Runway, ...   \n",
      "2  Op-Ed: Middlebury Must Rescind The Kraken’s Ho...   \n",
      "3  Student’s Instagram Story of Sunset Wins Pulit...   \n",
      "4  Unable To Go Down Ski Slope, Feb Grads Go Down...   \n",
      "\n",
      "                                                link  \n",
      "0  https://thelocalnoodle.com/2021/03/03/breaking...  \n",
      "1  https://thelocalnoodle.com/2021/02/22/virtue-f...  \n",
      "2  https://thelocalnoodle.com/2021/01/15/op-ed-mi...  \n",
      "3  https://thelocalnoodle.com/2020/11/19/students...  \n",
      "4  https://thelocalnoodle.com/2020/11/16/unable-t...  \n",
      "                                              Header  \\\n",
      "0  college poised to create education studies dua...   \n",
      "1              rises in financial aid cause deficits   \n",
      "2         russian journalist tikhon dzyadko to speak   \n",
      "3           evelin toth 17 awarded watson fellowship   \n",
      "4              student government association update   \n",
      "\n",
      "                                                Link  \n",
      "0  https://middleburycampus.com/35091/news/colleg...  \n",
      "1  https://middleburycampus.com/35093/news/rises-...  \n",
      "2  https://middleburycampus.com/35095/news/russia...  \n",
      "3  https://middleburycampus.com/35098/news/evelin...  \n",
      "4  https://middleburycampus.com/35101/news/studen...  \n"
     ]
    }
   ],
   "source": [
    "# let's get some text to play with ASAP -- \n",
    "from scraping_lib import fetch_all_campus, fetch_all_noodle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "n = fetch_all_noodle()\n",
    "c = fetch_all_campus()\n",
    "\n",
    "df_n = pd.DataFrame(n, columns=['Header', 'link'])\n",
    "\n",
    "df_c = pd.DataFrame(c, columns=['Header', 'Link'])\n",
    "\n",
    "\n",
    "print(df_n.head())\n",
    "print(df_c.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n['text'] = df_n['link'].apply(get_article_text_noodle)\n",
    "\n",
    "\n",
    "\n",
    "def get_article_text_noodle(link):\n",
    "    return 'todo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
